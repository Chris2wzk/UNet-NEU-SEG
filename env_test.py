#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯PyTorchå’ŒCUDAæ˜¯å¦æ­£ç¡®å®‰è£…
"""

import sys
import torch
import torchvision

def test_pytorch():
    """æµ‹è¯•PyTorchå®‰è£…"""
    print("=" * 50)
    print("PyTorchç¯å¢ƒæµ‹è¯•")
    print("=" * 50)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"Torchvisionç‰ˆæœ¬: {torchvision.__version__}")
    
    # CUDAä¿¡æ¯
    print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        print("CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
    
    # æµ‹è¯•åŸºæœ¬æ“ä½œ
    print("\næµ‹è¯•åŸºæœ¬å¼ é‡æ“ä½œ...")
    try:
        x = torch.randn(3, 3)
        y = torch.randn(3, 3)
        z = torch.mm(x, y)
        print("âœ“ åŸºæœ¬å¼ é‡æ“ä½œæ­£å¸¸")
    except Exception as e:
        print(f"âœ— åŸºæœ¬å¼ é‡æ“ä½œå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•CUDAæ“ä½œï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if torch.cuda.is_available():
        print("\næµ‹è¯•CUDAæ“ä½œ...")
        try:
            x_cuda = torch.randn(3, 3).cuda()
            y_cuda = torch.randn(3, 3).cuda()
            z_cuda = torch.mm(x_cuda, y_cuda)
            print("âœ“ CUDAæ“ä½œæ­£å¸¸")
        except Exception as e:
            print(f"âœ— CUDAæ“ä½œå¤±è´¥: {e}")
            return False
    
    print("\n" + "=" * 50)
    print("ç¯å¢ƒæµ‹è¯•å®Œæˆï¼")
    print("=" * 50)
    return True

if __name__ == "__main__":
    success = test_pytorch()
    if success:
        print("ğŸ‰ ç¯å¢ƒé…ç½®æˆåŠŸï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚")
    else:
        print("âŒ ç¯å¢ƒé…ç½®æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥å®‰è£…ã€‚")
        sys.exit(1) 